{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Recognition\n",
    "\n",
    "Term project for Machine Learning UoT course\n",
    "\n",
    "The objective of this Notebook is to predict the speaker of an English digit using a Keras model.\n",
    "\n",
    "This Notebook has three main sections.\n",
    "1. Extract the features of the WAV files, save them into CSV files and store them into Pandas\n",
    "2. The model will be trained based on the data set created by https://github.com/Jakobovski/free-spoken-digit-dataset\n",
    "3. The model will be re-trained based on the previous data plus the recordings made by Ankor (Indian accent), Caroline (Canadian female child accent) and Rodolfo (Brazilian accent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "\n",
    "The output of this section is the CSV files with the data to be handle by the model\n",
    "\n",
    "```\n",
    "trainData     : ../data/recordings/train \n",
    "testData      : ../data/recordings/test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"../data/csv/train.csv\"\n",
    "TEST_CSV_FILE = \"../data/csv/test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files creation is skipped\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"../data/recordings/trainData\", TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"../data/recordings/testData\", TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/csv/train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.025131        2263.257195         2423.742932  5037.060547   \n",
      "1  0.017434        1964.576479         2164.069455  4232.765174   \n",
      "2  0.032202        1558.989634         1983.256586  3471.613770   \n",
      "3  0.019922        2126.700450         2270.229736  4376.725107   \n",
      "4  0.029243        1576.336568         1936.231997  3177.870117   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.114467 -416.317078   93.509689  20.108961  33.628685   \n",
      "1            0.088604 -444.202728  104.891663   6.255211  39.115692   \n",
      "2            0.065241 -413.475189  112.861092  22.997181  35.574394   \n",
      "3            0.110794 -438.835358   95.439583  17.603657  37.666286   \n",
      "4            0.066458 -397.284363  109.741707  16.604698  43.763508   \n",
      "\n",
      "       mfcc5  ...    mfcc12     mfcc13     mfcc14    mfcc15     mfcc16  \\\n",
      "0   4.782962  ...  1.397505 -12.899868  -8.956563 -0.710121  -6.882756   \n",
      "1  10.545595  ...  2.888384 -15.642987 -13.738211 -2.906362 -10.828699   \n",
      "2   7.282945  ... -3.133941 -10.205274 -15.366270 -1.957181  -5.440994   \n",
      "3   9.626062  ...  2.533757  -8.088105 -10.803130 -1.590997  -7.822635   \n",
      "4  10.480644  ... -3.965786 -21.020741 -12.847131 -7.123433  -8.734676   \n",
      "\n",
      "     mfcc17     mfcc18    mfcc19    mfcc20  number  \n",
      "0 -1.573182  -3.581472 -5.625626  1.464069       1  \n",
      "1  2.248117  -7.669968 -6.090080 -0.770093       1  \n",
      "2 -2.761529 -12.085954 -3.433341 -0.794300       1  \n",
      "3 -1.712487  -3.166165 -7.187031  2.148904       1  \n",
      "4 -3.975639  -8.973385 -5.855656 -2.390283       1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "../data/csv/test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.026171        1976.092934         2256.741607  4188.037109   \n",
      "1  0.006209        1429.026778         2188.279135  3361.333008   \n",
      "2  0.030083        1447.607772         1943.238713  3217.060547   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4     mfcc5  \\\n",
      "0            0.092022 -406.176025   99.329926  13.063265  31.460566  7.021623   \n",
      "1            0.022132 -627.408875   98.451027  26.374922  21.451702  4.870950   \n",
      "2            0.054325 -418.588013  131.875839  24.485344  29.009775  8.678635   \n",
      "\n",
      "   ...    mfcc12     mfcc13     mfcc14    mfcc15    mfcc16     mfcc17  \\\n",
      "0  ... -2.228748 -16.088596 -12.063771 -2.754982 -7.659901  -4.323417   \n",
      "1  ...  0.097818  -2.724034   1.066525 -5.484253  6.603865  -8.808881   \n",
      "2  ...  1.716907  -4.746157  -2.479197 -8.693762  6.749485 -10.158951   \n",
      "\n",
      "     mfcc18    mfcc19    mfcc20  number  \n",
      "0 -6.064962 -6.094229  0.543286       1  \n",
      "1  2.380199 -5.429867 -0.317546       0  \n",
      "2 -1.765987 -5.782708  3.496445       2  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresbonding umnber\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName) # shape: 1470(0) x 28(1)\n",
    "    # we have six speakers: \n",
    "    # 0: Kazanin\n",
    "    # 1: Bednarsky \n",
    "    # 2: Theo\n",
    "    # 3: Ankur\n",
    "    # 4: Caroline\n",
    "    # 5: Rodolfo\n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "    #print(filenameArray)\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = filenameArray[i][0]\n",
    "        #print(speaker)\n",
    "        if speaker == \"k\":\n",
    "            speaker = 0\n",
    "        elif speaker == \"b\":\n",
    "            speaker = 1\n",
    "        elif speaker == \"z\":\n",
    "            speaker = 2\n",
    "        elif speaker == \"a\":\n",
    "            speaker = 3\n",
    "        elif speaker == \"c\":\n",
    "            speaker = 4\n",
    "        elif speaker == \"r\":\n",
    "            speaker = 5\n",
    "        else: \n",
    "            speaker = 6\n",
    "        #print(speaker)\n",
    "        speakerArray.append(speaker)\n",
    "    \n",
    "    data['number'] = speakerArray\n",
    "    \n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the speker of a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (137,)\n",
      "Y from validation data: (59,)\n",
      "Y from test data: (3,)\n",
      "(137,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Q06tYXcdQZFp",
    "outputId": "8ab73b51-7592-450c-b152-8746e2f11b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139    6\n",
      "113    6\n",
      "16     1\n",
      "75     0\n",
      "154    2\n",
      "185    2\n",
      "69     0\n",
      "55     0\n",
      "18     1\n",
      "169    2\n",
      "156    2\n",
      "15     1\n",
      "161    2\n",
      "60     0\n",
      "115    6\n",
      "114    6\n",
      "145    6\n",
      "9      1\n",
      "73     0\n",
      "187    2\n",
      "112    6\n",
      "93     0\n",
      "138    6\n",
      "45     1\n",
      "85     0\n",
      "67     0\n",
      "128    6\n",
      "173    2\n",
      "30     1\n",
      "68     0\n",
      "82     0\n",
      "119    6\n",
      "183    2\n",
      "24     1\n",
      "137    6\n",
      "95     0\n",
      "56     0\n",
      "19     1\n",
      "122    6\n",
      "76     0\n",
      "5      1\n",
      "65     0\n",
      "136    6\n",
      "97     0\n",
      "168    2\n",
      "123    6\n",
      "165    2\n",
      "12     1\n",
      "35     1\n",
      "162    2\n",
      "42     1\n",
      "66     0\n",
      "135    6\n",
      "78     0\n",
      "118    6\n",
      "124    6\n",
      "29     1\n",
      "132    6\n",
      "170    2\n",
      "Name: number, dtype: int64\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 77ms/step - loss: 2.1399 - accuracy: 0.2190 - val_loss: 1.5317 - val_accuracy: 0.7966\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 1.4777 - accuracy: 0.4818 - val_loss: 0.9500 - val_accuracy: 0.8814\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.9774 - accuracy: 0.7372 - val_loss: 0.5117 - val_accuracy: 0.9661\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.7737 - val_loss: 0.2618 - val_accuracy: 0.9831\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.4891 - accuracy: 0.8832 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8759 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2370 - accuracy: 0.9343 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1529 - accuracy: 0.9562 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1052 - accuracy: 0.9708 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0697 - accuracy: 0.9927 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1049 - accuracy: 0.9635 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0535 - accuracy: 0.9927 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0435 - accuracy: 0.9927 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0686 - accuracy: 0.9854 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0704 - accuracy: 0.9854 - val_loss: 8.3890e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 5.0563e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 3.3134e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 2.8571e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 2.6146e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 2.3045e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9854 - val_loss: 1.2898e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0345 - accuracy: 0.9854 - val_loss: 1.1940e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 1.2823e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9927 - val_loss: 1.6962e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.6447e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1382e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 9.2455e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 8.4374e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 0.9854 - val_loss: 5.4692e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 6.4770e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 5.6801e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 3.9489e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.2872e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7177e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4117e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.9117e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6135e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.2433e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3602e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.4657e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 0.9927 - val_loss: 1.3566e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9927 - val_loss: 4.7258e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9927 - val_loss: 4.2591e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9927 - val_loss: 4.1339e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.9927 - val_loss: 3.8914e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 0.9927 - val_loss: 2.9438e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 2.3922e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.1680e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9927 - val_loss: 1.7012e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.3012e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "#X_train = np.delete(X_train, len(X_train) - 1, axis = 1)\n",
    "#print(X_train)\n",
    "#model.summary()\n",
    "print(y_val)\n",
    "#Train with early stopping to avoid overfitting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "z3nvtYKVa5HD",
    "outputId": "b858b37f-8e47-4cb4-a737-ef960246254b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions to show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeaker(speaker):\n",
    "    #speaker = str(speaker)\n",
    "    if speaker == 0:\n",
    "        return \"Kazanin\"\n",
    "    elif speaker == 1:\n",
    "        return \"Bednarsky\"\n",
    "    elif speaker == 2:\n",
    "        return \"Zaikov\"\n",
    "    elif speaker == 3:\n",
    "        return \"Ankur\"\n",
    "    elif speaker == 4:\n",
    "        return \"Caroline\"\n",
    "    elif speaker == 5:\n",
    "        return \"Rodolfo\"\n",
    "    else: \n",
    "        speaker = \"Unknown\"\n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        prediction = getSpeaker(np.argmax(model.predict(X_data[i:i+1]), axis=-1)[0])\n",
    "        #deprecetad:  prediction = getSpeaker(model.predict_classes(X_data[i:i+1])[0])\n",
    "\n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "            print(\"Number={0:d}, y={1:10s}- prediction={2:10s}- match={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "            print(\"y={0:10s}- prediction={1:10s}- match={2}\".format(speaker, prediction, speaker==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    #Confution Matrix and Classification Report\n",
    "    Y_pred = model.predict_classes(X_data)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    target_names = [\"Jackson\", \"Nicola\", \"Theo\", \"Ankur\", \"Caroline\", \"Rodolfo\", \"Unknown\"]\n",
    "    print(classification_report(y_test_num, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "HSVxu84pRgZa",
    "outputId": "eb9242c9-7bff-4d54-a58c-60a915aad7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TEST DATA #\n",
      "\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 4.1063 - accuracy: 0.6667\n",
      "accuracy: 66.67%\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "y=Bednarsky - prediction=Bednarsky - match=True\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "y=Kazanin   - prediction=Zaikov    - match=False\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "y=Zaikov    - prediction=Zaikov    - match=True\n"
     ]
    }
   ],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Prediction\n",
    "printPrediction(X_test[0:100], y_test[0:100], False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "22c61a617fe55e4d9168a5346b2892267601016f55eef7b980b10e049206c964"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
