{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Recognition\n",
    "\n",
    "Term project for Machine Learning UoT course\n",
    "\n",
    "The objective of this Notebook is to predict the speaker of an English digit using a Keras model.\n",
    "\n",
    "This Notebook has three main sections.\n",
    "1. Extract the features of the WAV files, save them into CSV files and store them into Pandas\n",
    "2. The model will be trained based on the data set created by https://github.com/Jakobovski/free-spoken-digit-dataset\n",
    "3. The model will be re-trained based on the previous data plus the recordings made by Ankor (Indian accent), Caroline (Canadian female child accent) and Rodolfo (Brazilian accent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "\n",
    "The output of this section is the CSV files with the data to be handle by the model\n",
    "\n",
    "```\n",
    "trainData     : ../data/recordings/train \n",
    "testData      : ../data/recordings/test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If true, the WAV files will be read and their features will be saved in the CSV files\n",
    "# As this is the most time consuming task, only enable it if you don't have the CSV files yet\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"train_dima_tema.csv\"\n",
    "TEST_CSV_FILE = \"test_dima_tema.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder ../data/recordings/train_dima_tema will be saved to train_dima_tema.csv\n",
      "CSV Header:  ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n",
      "End of extractWavFeatures\n",
      "The features of the files in the folder ../data/recordings/test_dima_tema will be saved to test_dima_tema.csv\n",
      "CSV Header:  ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n",
      "End of extractWavFeatures\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        # remove leading and trailing silence\n",
    "        y, index = librosa.effects.trim(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"../data/recordings/train_dima_tema\", TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"../data/recordings/test_dima_tema\", TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dima_tema.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.018084        2259.898561         2605.302743  4955.658923   \n",
      "1  0.019266        1918.007737         2288.109517  4313.254395   \n",
      "2  0.021764        2578.502273         2747.677795  5452.745361   \n",
      "3  0.021328        2215.125059         2575.241345  5023.087742   \n",
      "4  0.014061        2725.053509         2758.626914  5812.469482   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.083650 -440.503540  104.727837  15.690970   9.861130   \n",
      "1            0.074072 -458.920410  109.328217   7.701780  14.556528   \n",
      "2            0.104036 -379.547791   95.150368  20.285648  12.775127   \n",
      "3            0.078698 -401.235046   99.709312  12.692218  17.790264   \n",
      "4            0.100484 -434.119995   92.505531  21.977360   3.039394   \n",
      "\n",
      "       mfcc5  ...    mfcc12     mfcc13     mfcc14     mfcc15    mfcc16  \\\n",
      "0  17.637451  ...  2.969013 -14.605819  10.184173  -9.190934  5.590312   \n",
      "1  11.188511  ...  0.284270  -8.045336   7.252040  -7.374241  4.976208   \n",
      "2  20.834656  ...  4.704387 -15.116961  11.278474 -12.566614  8.559793   \n",
      "3  17.600241  ...  8.354834 -11.809557   5.386767  -2.792585  3.378271   \n",
      "4  14.697981  ...  6.838908 -15.814137  11.640592  -6.988208  7.572773   \n",
      "\n",
      "      mfcc17    mfcc18    mfcc19    mfcc20  number  \n",
      "0  -0.985651  1.861579 -2.977754  4.295450       0  \n",
      "1  -4.298592  1.399508 -1.983967 -1.965064       0  \n",
      "2  -6.948930  0.351161 -5.920290  1.051007       0  \n",
      "3 -10.911419  5.877841 -9.259444  0.477892       0  \n",
      "4  -1.210312  1.110429 -7.234458  4.913230       0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "test_dima_tema.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.015498        2036.316206         2341.229183  4478.906250   \n",
      "1  0.026171        1976.092934         2256.741607  4188.037109   \n",
      "2  0.006796         911.441391          895.433124  1995.666504   \n",
      "3  0.015498        2036.316206         2341.229183  4478.906250   \n",
      "4  0.026171        1976.092934         2256.741607  4188.037109   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.080930 -464.053802  114.462791  16.191341  10.367159   \n",
      "1            0.092022 -406.176025   99.329926  13.063265  31.460566   \n",
      "2            0.036482 -547.544678  219.518341 -60.242069  17.053772   \n",
      "3            0.080930 -464.053802  114.462791  16.191341  10.367159   \n",
      "4            0.092022 -406.176025   99.329926  13.063265  31.460566   \n",
      "\n",
      "       mfcc5  ...     mfcc12     mfcc13     mfcc14     mfcc15    mfcc16  \\\n",
      "0  16.298548  ...   4.051403 -14.331759  10.487463 -10.849960  7.501403   \n",
      "1   7.021623  ...  -2.228748 -16.088596 -12.063771  -2.754982 -7.659901   \n",
      "2  40.544239  ... -28.285969   2.758897  -8.252637 -16.315981  7.705584   \n",
      "3  16.298548  ...   4.051403 -14.331759  10.487463 -10.849960  7.501403   \n",
      "4   7.021623  ...  -2.228748 -16.088596 -12.063771  -2.754982 -7.659901   \n",
      "\n",
      "     mfcc17     mfcc18    mfcc19    mfcc20  number  \n",
      "0 -6.059965  -0.012275 -0.848337 -0.684365       0  \n",
      "1 -4.323417  -6.064962 -6.094229  0.543286       1  \n",
      "2 -7.336659 -12.691132  5.128728 -9.363704       2  \n",
      "3 -6.059965  -0.012275 -0.848337 -0.684365       0  \n",
      "4 -4.323417  -6.064962 -6.094229  0.543286       1  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresbonding umnber\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName) # shape: 1470(0) x 28(1)\n",
    "    # we have six speakers: \n",
    "    # 0: Jackson\n",
    "    # 1: Nicolas \n",
    "    # 2: Theo\n",
    "    # 3: Ankur\n",
    "    # 4: Caroline\n",
    "    # 5: Rodolfo\n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "    #print(filenameArray)\n",
    "    for i in range(len(filenameArray)):\n",
    "        speaker = filenameArray[i][2]\n",
    "        #print(speaker)\n",
    "        if speaker == \"j\":\n",
    "            speaker = 0\n",
    "        elif speaker == \"n\":\n",
    "            speaker = 1\n",
    "        elif speaker == \"t\":\n",
    "            speaker = 2\n",
    "        elif speaker == \"a\":\n",
    "            speaker = 3\n",
    "        elif speaker == \"c\":\n",
    "            speaker = 4\n",
    "        elif speaker == \"r\":\n",
    "            speaker = 5\n",
    "        else: \n",
    "            speaker = 6\n",
    "        #print(speaker)\n",
    "        speakerArray.append(speaker)\n",
    "    \n",
    "    data['number'] = speakerArray\n",
    "    \n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "\n",
    "The model will be trained to predict the speker of a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (1029,)\n",
      "Y from validation data: (441,)\n",
      "Y from test data: (30,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X from training data (1029, 25)\n",
      "X from validation data (441, 25)\n",
      "X from test data (30, 25)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n",
    "print(\"X from test data\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Q06tYXcdQZFp",
    "outputId": "8ab73b51-7592-450c-b152-8746e2f11b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               6656      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,458\n",
      "Trainable params: 48,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 2s 83ms/step - loss: 1.9823 - accuracy: 0.3168 - val_loss: 1.0599 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.9243 - accuracy: 0.8134 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3346 - accuracy: 0.9495 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.1287 - accuracy: 0.9718 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0535 - accuracy: 0.9913 - val_loss: 4.7812e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0423 - accuracy: 0.9942 - val_loss: 1.6249e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9922 - val_loss: 7.7236e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 4.1710e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 2.8000e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 2.0147e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 1.4977e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 1.1213e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0174 - accuracy: 0.9971 - val_loss: 8.5794e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 6.9237e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 5.5031e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 4.3694e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 3.2566e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 2.6120e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 2.1295e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7267e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3280e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.0180e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 7.7445e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 6.0875e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.0414e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.3142e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.6979e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 2.9789e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4491e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0895e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.7489e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.5678e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.2624e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0623e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.2988e-08 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.1635e-08 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 9.3646e-04 - accuracy: 1.0000 - val_loss: 6.8930e-08 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9961 - val_loss: 6.2984e-08 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.8658e-08 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 5.3252e-08 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.7576e-08 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 4.3521e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.7033e-08 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 3.2708e-08 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 2.8383e-08 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.5950e-08 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 5.4966e-04 - accuracy: 1.0000 - val_loss: 2.3517e-08 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 1.9733e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7571e-08 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5138e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "#X_train = np.delete(X_train, len(X_train) - 1, axis = 1)\n",
    "#print(X_train)\n",
    "model.summary()\n",
    "#Train with early stopping to avoid overfitting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "z3nvtYKVa5HD",
    "outputId": "b858b37f-8e47-4cb4-a737-ef960246254b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions to show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeaker(speaker):\n",
    "    #speaker = str(speaker)\n",
    "    if speaker == 0:\n",
    "        return \"Jackson\"\n",
    "    elif speaker == 1:\n",
    "        return \"Nicola\"\n",
    "    elif speaker == 2:\n",
    "        return \"Theo\"\n",
    "    elif speaker == 3:\n",
    "        return \"Ankur\"\n",
    "    elif speaker == 4:\n",
    "        return \"Caroline\"\n",
    "    elif speaker == 5:\n",
    "        return \"Rodolfo\"\n",
    "    else: \n",
    "        speaker = \"Unknown\"\n",
    "        \n",
    "def printPrediction(X_data, y_data, printDigit):\n",
    "    print('\\n# Generate predictions')\n",
    "    for i in range(len(y_data)):\n",
    "        prediction = getSpeaker(np.argmax(model.predict(X_data[i:i+1]), axis=-1)[0])\n",
    "        #deprecetad:  prediction = getSpeaker(model.predict_classes(X_data[i:i+1])[0])\n",
    "\n",
    "        speaker = getSpeaker(y_data[i])\n",
    "        if printDigit == True:\n",
    "            print(\"Number={0:d}, y={1:10s}- prediction={2:10s}- match={3}\".format(i, speaker, prediction, speaker==prediction))\n",
    "        else:\n",
    "            print(\"y={0:10s}- prediction={1:10s}- match={2}\".format(speaker, prediction, speaker==prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(X_data, y_data):\n",
    "    #Confution Matrix and Classification Report\n",
    "    Y_pred = model.predict_classes(X_data)\n",
    "    y_test_num = y_data.astype(np.int64)\n",
    "    conf_mt = confusion_matrix(y_test_num, Y_pred)\n",
    "    print(conf_mt)\n",
    "    plt.matshow(conf_mt)\n",
    "    plt.show()\n",
    "    print('\\nClassification Report')\n",
    "    target_names = [\"Jackson\", \"Nicola\", \"Theo\", \"Ankur\", \"Caroline\", \"Rodolfo\", \"Unknown\"]\n",
    "    print(classification_report(y_test_num, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Present the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "HSVxu84pRgZa",
    "outputId": "eb9242c9-7bff-4d54-a58c-60a915aad7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# TEST DATA #\n",
      "\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n",
      "\n",
      "# Generate predictions\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "y=Jackson   - prediction=Jackson   - match=True\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "y=Nicola    - prediction=Nicola    - match=True\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "y=Theo      - prediction=Theo      - match=True\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "y=Jackson   - prediction=Jackson   - match=True\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "y=Nicola    - prediction=Nicola    - match=True\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "y=Theo      - prediction=Theo      - match=True\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "y=Jackson   - prediction=Jackson   - match=True\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "y=Nicola    - prediction=Nicola    - match=True\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "y=Theo      - prediction=Theo      - match=True\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "y=Jackson   - prediction=Jackson   - match=True\n"
     ]
    }
   ],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Prediction\n",
    "printPrediction(X_test[0:10], y_test[0:10], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "report(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3\n",
    "\n",
    "There are 50 recordings for each digit for each speaker: Jackson, Nicolas and Theo (total 1500 recordings)\n",
    "Training data has 49 recordings for each digit for each speaker: 1470 recordings total.\n",
    "Test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "In addition, there are 2 recordings for each digit for each speaker: Ankur, Caroline and Rodolfo (total 60 recordings)\n",
    "This addition training data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "This addition test data has 1 recordings for each digit for each speaker: 30 recordings total.\n",
    "\n",
    "Therefore the full data set has:\n",
    "* Training: 1500 recordings\n",
    "* Training: 60 recordings\n",
    "\n",
    "The data used here comes from the recordings stored in:\n",
    "* ../data/recordings/train\n",
    "* ../data/recordings/test\n",
    "* ../data/recordings/moreSpeakersTrain\n",
    "* ../data/recordings/moreSpeakersTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fullTrainData = trainData.append(moreTrainData)\n",
    "\n",
    "X = np.array(fullTrainData.iloc[:, :-1], dtype = float)\n",
    "y = fullTrainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "X_more_test = np.array(moreTestData.iloc[:, :-1], dtype = float)\n",
    "y_more_test = moreTestData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from validation data:\", y_val.shape)\n",
    "print(\"Y from test data:\", y_test.shape)\n",
    "print(\"Y from other speakers test data:\", y_more_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "X_more_test = scaler.transform( X_more_test )\n",
    "\n",
    "print(\"X from training data\", X_train.shape)\n",
    "print(\"X from validation data\", X_val.shape)\n",
    "print(\"X from test data\", X_test.shape)\n",
    "print(\"X from other speakers test data\", X_more_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "#Train with early stopping to avoid overfitting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=128, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Present the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Prediction\n",
    "printPrediction(X_test[0:10], y_test[0:10], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# OTHER SPEAKERS DATA #\\n')\n",
    "score = model.evaluate(X_more_test, y_more_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Prediction\n",
    "printPrediction(X_more_test[0:10], y_more_test[0:10], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Test Data\\n\")\n",
    "report(X_test, y_test)\n",
    "\n",
    "print(\"Classification Report for Other Speakers\\n\")\n",
    "report(X_more_test, y_more_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "22c61a617fe55e4d9168a5346b2892267601016f55eef7b980b10e049206c964"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
